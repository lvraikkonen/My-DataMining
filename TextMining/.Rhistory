install.packages('rJava')
library(tm)
install.packages("Rwordseg", repos="http://R-Forge.R-project.org", type="source")
library("rJava", lib.loc="C:/Users/v-shuolv/Documents/R/win-library/3.1")
Sys.getenv("JAVA_HOME")
library(rJava)
library(rJava)
library(tm)
library(Rwordseg)
library(RTextTools)
library(FSelector)
install.packages("Rwordseg", repos="http://R-Forge.R-project.org", type="source")
install.packages("Rwordseg", repos="http://R-Forge.R-project.org")
install.packages("~/Rwordseg_0.2-1.zip", repos = NULL)
library(tm)
library(Rwordseg)
library(RTextTools)
library(FSelector)
teststring1 <- "我是一个俗人"
teststring1
segmentCN(teststring1)
segmentCN(c("`(¢3n", "g5õa"))
teststring1 <- "我沉默不代表我不痛我不痛眼泪就不会流总是安静承受安静忍受安静看你走你说我很适合当朋友"
segmentCN(teststring1)
library(Rwordseg)
teststring <- "采用两种粒度的搜索粗粒度和细粒度"
segmentCN(teststring)
set.seed(1)
rpois(5, 2)
a <- rpois(5, 2)
mode(a)
library(datasets)
Rprof()
fit <- lm(y ~ x1 + x2)
Rprof(NULL)
library(datasets)
Rprof()
fit <- lm(y ~ x1 + x2)
summaryRprof()
y <- rnorm(10)
download.file('https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv')
?download.file
url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv'
destFile <- "./data.csv"
download.file(url,destFile,method="curl")
library(httr)
library(httpuv)
library(jsonlite)
?oauth_app
oauth_endpoints("twitter")
# 2. Register an application at https://github.com/settings/applications
# Insert your values below - if secret is omitted, it will look it up in the
# GITHUB_CONSUMER_SECRET environmental variable.  Use http://localhost:1410
# as the callback url
myapp <- oauth_app("ContentMining", "an3hwBQXNU7xwZmz3ISTHHryI", secret = " I5pMQT5Hlh7G3zHhIBmmTC2f0AKCrJKBem69eTygwpfRu9hNBj")
# 3. Get OAuth credentials
twitter_token <- oauth2.0_token(oauth_endpoints("twitter"), myapp)
oauth_endpoints("twitter")
myapp <- oauth_app("ContentMining", "an3hwBQXNU7xwZmz3ISTHHryI", secret = " I5pMQT5Hlh7G3zHhIBmmTC2f0AKCrJKBem69eTygwpfRu9hNBj")
twitter_token <- oauth2.0_token(oauth_endpoints("twitter"), myapp)
# 3. Get OAuth credentials
twitter_token <- oauth1.0_token(oauth_endpoints("twitter"), myapp)
myapp <- oauth_app("ContentMining", key = "an3hwBQXNU7xwZmz3ISTHHryI",
secret = " I5pMQT5Hlh7G3zHhIBmmTC2f0AKCrJKBem69eTygwpfRu9hNBj")
twitter_token <- oauth1.0_token(oauth_endpoints$twitter, myapp)
twitter_token <- oauth2.0_token(oauth_endpoints$twitter, myapp)
twitter_token <- oauth2.0_token(oauth_endpoints("twitter"), myapp)
# 3. Get OAuth credentials
twitter_token <- oauth1.0_token(oauth_endpoints("twitter"), myapp)
myapp <- oauth_app("ContentMining", key = "an3hwBQXNU7xwZmz3ISTHHryI",
secret = "I5pMQT5Hlh7G3zHhIBmmTC2f0AKCrJKBem69eTygwpfRu9hNBj")
twitter_token <- oauth1.0_token(oauth_endpoints("twitter"), myapp)
twitter_token <- oauth2.0_token(oauth_endpoints("twitter"), myapp)
twitter_token <- oauth2.0_token(oauth_endpoints("twitter"), myapp)
req <- GET("https://api.twitter.com/1.1/statuses/home_timeline.json",
config(token = twitter_token))
req <- GET("https://api.twitter.com/1.1/statuses/home_timeline.json",
config(token = twitter_token))
req <- GET("https://api.twitter.com/1.1/statuses/home_timeline.json",
config(token = twitter_token))
stop_for_status(req)
content(req)
?GET
install.packages("twitteR")
library(twitteR)
api_key <- "an3hwBQXNU7xwZmz3ISTHHryI"
api_secret <- "I5pMQT5Hlh7G3zHhIBmmTC2f0AKCrJKBem69eTygwpfRu9hNBj"
access_token <- "174593932-saf9FxbAiAW1KwSHoYrubL1yuT4Or6Q9OvIc8Ppt"
access_token_secret <- "AA0ft0RJLbZz5mColacJZ37imPDp7pt6nS55AJNg"
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
?setup_twitter_oauth
?searchTwitter
mh370 <- searchTwitter("#PrayForMH370", since = "2014-03-08", until = "2014-03-20", n = 1000)
myapp <- oauth_app("ContentMining", key = "an3hwBQXNU7xwZmz3ISTHHryI",
secret = "I5pMQT5Hlh7G3zHhIBmmTC2f0AKCrJKBem69eTygwpfRu9hNBj")
# 3. Get OAuth credentials
twitter_token <- oauth2.0_token(oauth_endpoints("twitter"), myapp)
mh370 <- searchTwitter("#PrayForMH370", since = "2014-03-08", until = "2014-03-20", n = 1000)
？tm
?tm
library("tm", lib.loc="C:/Users/v-shuolv/Documents/R/win-library/3.1")
library(Rwordseg)
teststring1 <- "或是当事人在第一时间出来辟谣，已远远不能满足如今网络信息传播的速度，而虚假的信息往往给政府、企业、及知名人士带来负面的影响，如金庸去世，到近期所谓铁观音迷魂抢劫引发网民恐慌."
segmentCN(teststring1)
library(tm)
library(Rwordseg)
library(RTextTools)
library(FSelector)
Infor.sweet <- read.csv("Data/sweetsong.csv", header = TRUE)
Infor.sad <- read.csv("Data/sadsong.csv", header = TRUE)
View(Infor.sweet)
removeEnglish <- function(x) {
gsub("[a-z]+|[A-Z]+", "", x)
}
a <- removeEnglish("asfasfasdf我是汉语")
a
b <- removeEnglish("asfasfasdf我是a汉语")
b
?segmentCn
?segmentCN
s <- Infor.sweet$lyric
s
word_s <- lapply(Infor.sweet$lyric,removeEnglish)
class(word_s)
head(word_s)
Infor.sweet <- read.csv("Data/sweetsong.csv",encoding="UTF-8",  header = TRUE)
Infor.sad <- read.csv("Data/sadsong.csv",encoding="UTF-8",  header = TRUE)
word_s <- lapply(Infor.sweet$lyric,removeEnglish)
head(word_s)
word_s <- lapply(word_s,segmentCN)
head(word_s)
# 形成corpus
song.sad.corpus <- corpus(song.sad)
song.sweet.corpus <- corpus(song.sweet)
# 合成甜蜜和伤感的语料库
song.corpus <- c(song.sad.corpus, song.sweet.corpus)
?Corpus
makeCorpus <- function(str1, str2) {
# 伤感歌曲分词 组成语料库
word.sad <- lapply(str1, removeEnglish)
word.sad <- lapply(word.sad, segmentCN)
corpus.sad <- Corpus(VectorSource(word.sad))
# 甜蜜歌曲分词 组成语料库
word.sweet <- lapply(str2, removeEnglish)
word.sweet <- lapply(word.sweet, segmentCN)
corpus.sweet <- Corpus(VectorSource(word.sweet))
# 合成预料库
corpus <- c(corpus.sad, corpus.sweet)
return(corpus)
}
# 形成corpus
song.sad.corpus <- corpus(song.sad)
song.sweet.corpus <- corpus(song.sweet)
# 合成甜蜜和伤感的语料库
song.corpus <- c(song.sad.corpus, song.sweet.corpus)
corpus <- makeCorpus(Infor.sweet$lyric, Infor.sad$lyric)
str(corpus)
dtm <- function(corpus, tfidf = FALSE) {
## 读取停止词
mystopwords <- readLines("material/stopwords.txt")
if (tfidf == TRUE) {
## 文档-词矩阵 词的长度大于1就纳入矩阵
cor.dtm <- DocumentTermMatrix(corpus, control = list(wordLengths = c(2,
Inf), stopwords = mystopwords, weighting = weightTfIdf))
} else {
cor.dtm <- DocumentTermMatrix(corpus, control = list(wordLengths = c(2,
Inf), stopwords = mystopwords))
}
## 去掉稀疏矩阵中低频率的词
cor.dtm <- removeSparseTerms(cor.dtm, 0.98)
## 使得每一行至少有一个词不为0 rowTotals <- apply(cor.dtm, 1, sum) cor.dtm <-
## cor.dtm[rowTotals > 0]
return(cor.dtm)
}
dtm <- function(corpus, tfidf = FALSE) {
## 读取停止词
mystopwords <- readLines("Data/stopwords.txt")
if (tfidf == TRUE) {
## 文档-词矩阵 词的长度大于1就纳入矩阵
cor.dtm <- DocumentTermMatrix(corpus, control = list(wordLengths = c(2,
Inf), stopwords = mystopwords, weighting = weightTfIdf))
} else {
cor.dtm <- DocumentTermMatrix(corpus, control = list(wordLengths = c(2,
Inf), stopwords = mystopwords))
}
## 去掉稀疏矩阵中低频率的词
cor.dtm <- removeSparseTerms(cor.dtm, 0.98)
## 使得每一行至少有一个词不为0 rowTotals <- apply(cor.dtm, 1, sum) cor.dtm <-
## cor.dtm[rowTotals > 0]
return(cor.dtm)
}
corpus.dtm <- dtm(corpus)
corpus.dtm.tfidf <- dtm(corpus, tfidf = TRUE)
song.sweet.wordcloud <- wordCloud(corpus.dtm.tfidf)
install.packages('wordcloud')
library(wordcloud)
song.sweet.wordcloud <- wordCloud(corpus.dtm.tfidf)
?wordcloud
song.sweet.wordcloud <- wordcloud(corpus.dtm.tfidf)
corpus.dtm.tfidf
corpus.dtm
inspect(corpus.dtm)
inspect(corpus.dtm.tfidf)
song.sweet.wordcloud <- wordcloud(corpus.dtm.tfidf)
m <- as.matrix(corpus.dtm.tfidf)
v <- sort(rowSums(m),decreasing=TRUE)
m
d <- data.frame(word = names(v),freq=v)
d
head(d)
wordcloud(d$word,d$freq)
install.packages("Rweibo")
install.packages("Rweibo",repos = "http://R-Forge.R-project.org")
install.packages(“Rweibo”, repos=c(“http://jliblog.com/cran”, “http://cran.r-project.org”))
install.packages("Rweibo", repos=c("http://jliblog.com/cran", "http://cran.r-project.org"))
install.packages("Rweibo", repos = "http://R-Forge.R-project.org")
install.packages("~/Rweibo_0.2-2.tar.gz", repos = NULL, type = "source")
library("Rweibo", lib.loc="C:/Users/v-shuolv/Documents/R/win-library/3.1")
?registerApp
require("Rweibo")
registerApp(app_name="rdemo_lvraikkonen",
app_key="2174032425",
app_secret="9022f736db5184be5166d4a33969bf61")
listApp("rdemo_lvraikkonen")
?createOAuth
roauth <- createOAuth(app_name = "rdemo_lvraikkonen", access_name = "lvraikkonen")
roauth <- createOAuth(app_name = "rdemo_lvraikkonen", access_name = "rweibo",
login = TRUE, username = "lvraikkonen", password = "030006238")
roauth <- createOAuth(app_name = "rdemo_lvraikkonen", access_name = "rweibo")
roauth <- createOAuth(app_name = "rdemo_lvraikkonen", access_name = "rweibo")
roauth <- createOAuth(app_name = "rdemo_lvraikkonen", access_name = "rweibo")
roauth <- createOAuth(app_name = "rdemo_lvraikkonen", access_name = "rweibo")
roauth <- createOAuth(app_name = "rdemo_lvraikkonen", access_name = "lvraikkonen")
roauth <- createOAuth(app_name = "rdemo_lvraikkonen", access_name = "lvraikkonen",
login = TRUE, username = "lvraikkonen", password = "030006238")
roauth <- createOAuth(app_name = "rdemo_lvraikkonen", access_name = "lvraikkonen",
login = TRUE, username = "lvraikkonen", password = "030006238")
roauth <- createOAuth(app_name = "rdemo_lvraikkonen", access_name = "lvraikkonen",
login = TRUE, username = "lvraikkonen", password = "030006238")
require("Rweibo")
registerApp(app_name="text_mining_R",
app_key="3154041990",
app_secret="b817f3a4f74f51af23b26d7582dffd68")
roauth <- createOAuth(app_name = "text_mining_R", access_name = "lvraikkonen")
roauth <- createOAuth(app_name = "text_mining_R", access_name = "lvraikkonen")
roauth <- createOAuth(app_name = "text_mining_R", access_name = "lvraikkonen",
login = TRUE, username = "lvraikkonen", password = "030006238")
roauth <- createOAuth("text_mining_R", "lvraikkonen")  # 创建OAuth对象
roauth
roauth <- createOAuth(app_name = "text_mining_R", access_name = "lvraikkonen")
oauthobj <- new("weibo2.0", appName = "text_mining_R", oauthName = "lvraikkonen")
roauth <- createOAuth(app_name = "text_mining_R", access_name = "lvraikkonen")
library("ROAuth")
library("twitteR")
library("wordcloud")
library("tm")
download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.pem")
cred <- OAuthFactory$new(consumerKey='an3hwBQXNU7xwZmz3ISTHHryI',
consumerSecret='I5pMQT5Hlh7G3zHhIBmmTC2f0AKCrJKBem69eTygwpfRu9hNBj',
requestURL='https://api.twitter.com/oauth/request_token',
accessURL='http://api.twitter.com/oauth/access_token',
authURL='http://api.twitter.com/oauth/authorize')
cred$handshake(cainfo="cacert.pem")
cred <- OAuthFactory$new(consumerKey='an3hwBQXNU7xwZmz3ISTHHryI',
consumerSecret='I5pMQT5Hlh7G3zHhIBmmTC2f0AKCrJKBem69eTygwpfRu9hNBj',
requestURL='https://api.twitter.com/oauth/request_token',
accessURL='https://api.twitter.com/oauth/access_token',
authURL='https://api.twitter.com/oauth/authorize')
cred$handshake(cainfo="cacert.pem")
cred$handshake(cainfo="cacert.pem")
oauth_endpoints("twitter")
library(httr)
library(httpuv)
library(jsonlite)
# 1. Find OAuth settings for twitter
oauth_endpoints("twitter")
# 2. Register an application at https://github.com/settings/applications
# Insert your values below - if secret is omitted, it will look it up in the
# GITHUB_CONSUMER_SECRET environmental variable.  Use http://localhost:1410
# as the callback url
myapp <- oauth_app("ContentMining", key = "an3hwBQXNU7xwZmz3ISTHHryI",
secret = "I5pMQT5Hlh7G3zHhIBmmTC2f0AKCrJKBem69eTygwpfRu9hNBj")
twitter_token <- oauth2.0_token(oauth_endpoints("twitter"), myapp)
twitter_token <- oauth1.0_token(oauth_endpoints("twitter"), myapp)
req <- GET("https://api.twitter.com/1.1/statuses/home_timeline.json",
config(token = twitter_token))
stop_for_status(req)
content(req)
#Download SSL certification
download.file(url="http://curl.haxx.se/ca/cacert.pem", destfile="cacert.pem")
# Set SSL certs globally
options(RCurlOptions = list(cainfo = system.file("CurlSSL", "cacert.pem", package = "RCurl")))
#Set constant request URL
requestURL<-"https://api.twitter.com/oauth/request_token"
#Set constant accessURL
accessURL<-"https://api.twitter.com/oauth/access_token"
#set constant authURL
authURL<-"https://api.twitter.com/oauth/authorize"
consumerKey<-"an3hwBQXNU7xwZmz3ISTHHryI"
consumerSecret<-"I5pMQT5Hlh7G3zHhIBmmTC2f0AKCrJKBem69eTygwpfRu9hNBj"
twitCred <- OAuthFactory$new(consumerKey=consumerKey,
consumerSecret=consumerSecret,
requestURL=requestURL,
accessURL=accessURL,
authURL=authURL)
twitCred
str(twitCred)
twitCred$handshake(cainfo = system.file("CurlSSL", "cacert.pem",package = "RCurl"))
twitCred$handshake(cainfo = system.file("CurlSSL", "cacert.pem",package = "RCurl"))
twitCred$handshake(cainfo = system.file("CurlSSL", "cacert.pem",package = "RCurl"))
str(twitCred)
registerTwitterOAuth(twitCred)
## To check and see if the handshake worked
registerTwitterOAuth(twitCred)
##  save the handshake
save(list="twitCred", file="twitteR_credentials")
mynypd<-searchTwitter("#mynypd", n=200, cainfo="cacert.pem")
mynypd
mynypd <- searchTwitter("#WorldCup2014", n=100, cainfo="cacert.pem")
worldCup <- searchTwitter("#WorldCup2014", n=100, cainfo="cacert.pem")
worldCup
str(worldCup)
worldCup$text
worldCup[1]$text
worldCup$getText()
aaa <- sapply(worldCup,function(x) x$getText())
aaa
text <- sapply(worldCup,function(x) x$getText())
my_corpus <- Corpus(VectorSource(text))
my_corpus
inspect(my_corpus)
worldCup <- searchTwitter("#WorldCup2014", n=100, cainfo="cacert.pem")
worldCup_text <- sapply(worldCup, function(x) x$getText())
worldCup_corpus<-Corpus(VectorSource(worldCup_text))
worldCup_corpus<-tm_map(worldCup_corpus, tolower, mc.cores=1)
worldCup_corpus<-tm_map(worldCup_corpus, removePunctuation, mc.cores=1)
worldCup_corpus<-tm_map(worldCup_corpus, function(x) removeWords(x,stopwords()))
inspect(worldCup_corpus)
wordcloud(worldCup_corpus)
wordcloud(worldCup_corpus)
?knir()
library(knitr)
?knit
knit("AccessTwitter.Rmd","accessTwitter.md")
library(knitr)
knit("CaseStudy.Rmd","CaseStudy.md")
library("wordcloud", lib.loc="C:/Users/v-shuolv/Documents/R/win-library/3.1")
knit("CaseStudy.Rmd","CaseStudy.md")
knit("CaseStudy.Rmd","CaseStudy.md")
corpus.df <- as.data.frame(inspect(corpus.dtm.tfidf))
label<-factor(c(rep("sad",764),c(rep("sweet",861))))
weights.rf <- random.forest.importance(label~., corpus.df, 1)
library(RTextTools)
library(FSelector)
weights.rf <- random.forest.importance(label~., corpus.df, 1)
weights.rf <- random.forest.importance(label~., corpus.df, 1)
?random.forest.importance
corpus.df <- as.data.frame(inspect(corpus.dtm.tfidf),encoding="UTF-8")
View(corpus.df)
inspect(corpus.dtm.tfidf)
corpus.df <- as.data.frame(inspect(corpus.dtm.tfidf),encoding="UTF-8",stringsAsFactors=FALSE)
weights.rf <- random.forest.importance(label~., corpus.df, 1)
corpus.df <- as.data.frame(inspect(corpus.dtm.tfidf),encoding="Unicode",stringsAsFactors=FALSE)
str(corpus.df)
sessionInfo()
options(enc='utf8')
sessionInfo()
Encoding()
Encoding("我")
install.packages(c("RTextTools","topicmodels"))
install.packages(c("RTextTools","topicmodels"))
library(RTextTools)
library(topicmodels)
install.packages("topcimodels")
install.packages("C:/Users/v-shuolv/Downloads/topicmodels_0.2-1.tar.gz", repos = NULL, type = "source")
install.packages("C:/Users/v-shuolv/Downloads/topicmodels_0.2-1.zip", repos = NULL)
library(RTextTools)
library(topicmodels)
data(NYTimes)
data <- NYTimes[sample(1:3100,size=1000,replace=FALSE),]
library("knitr", lib.loc="C:/Users/v-shuolv/Documents/R/win-library/3.1")
knit("LDA.Rmd","LDA.md")
knit("LDA.Rmd","LDA.md")
install.packages(c("RTextTools", "topicmodels"))
knit("LDA.Rmd","LDA.md")
?create_matrix
matrix <- create_matrix(cbind(as.vector(data$Title),as.vector(data$Subject)), language="english", removeNumbers=TRUE, stemWords=TRUE, weighting=weightTf)
matrix <- create_matrix(cbind(as.vector(data$Title),as.vector(data$Subject)), language="english", removeNumbers=TRUE, stemWords=TRUE, weighting=weightTf)
matrix <- create_matrix(cbind(as.vector(data$Title),as.vector(data$Subject)), language="english", removeNumbers=FALSE, stemWords=FALSE, removePunctuation=FALSE, weighting=weightTfIdf)
data$Title
data$Subject
matrix <- create_matrix(cbind(as.vector(data$Title),as.vector(data$Subject)), language="english", removeNumbers=FALSE, stemWords=FALSE, removePunctuation=FALSE, weighting=weightTfIdf)
?weightTfIdf
library(tm)
?weightTfIdf
matrix <- create_matrix(cbind(as.vector(data$Title),as.vector(data$Subject)), language="english", removeNumbers=FALSE, stemWords=FALSE, removePunctuation=FALSE, weighting=weightTfIdf)
knit("LDA.Rmd","LDA.md")
k <- length(unique(data$Topic.Code))
k
?LDA
matrix
lda <- LDA(matrix,k)
matrix <- create_matrix(cbind(as.vector(data$Title),as.vector(data$Subject)), language="english", removeNumbers=FALSE, stemWords=FALSE, removePunctuation=FALSE, weighting=weightTf)
k <- length(unique(data$Topic.Code))
lda <- LDA(matrix, k)
terms(lda)
topics(lda)
knit("LDA.Rmd","LDA.md")
View(data)
?NYTimes
