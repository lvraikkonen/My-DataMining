{
    "contents" : "歌词分类研究 Folk from phenix502/music \n========================================================\n\n介绍如何使用R语言，进行文本情感分类研究。\n\n\n## 1 加载包\n\n\n各个package的主要功能如下：\n\n\n+ tm 形成文档词条矩阵\n+ Rwordseg 中文分词\n+ FSelector 特征提取，有chi-square，information gain等等\n+ RTextTools 文本挖掘分类算法,我这里用到的是随机森林和SVM\n\n\n```{r}\nlibrary(tm)\nlibrary(Rwordseg)\nlibrary(RTextTools)\nlibrary(FSelector)\n\n```\n\n## 2 读取歌词文本\n\n读取`.csv`文件`sweetsong.csv`和`sadsong.csv`\n\n爬虫(略)\n\n```{r Read source files}\nInfor.sweet <- read.csv(\"Data/sweetsong.csv\",encoding=\"UTF-8\",  header = TRUE)\nInfor.sad <- read.csv(\"Data/sadsong.csv\",encoding=\"UTF-8\",  header = TRUE)\n```\n\n\n## 3 分词并形成语料库\n```{r}\nremoveEnglish <- function(x) {\n    gsub(\"[a-z]+|[A-Z]+\", \"\", x)\n}\n\nmakeCorpus <- function(str1, str2) {\n    # 伤感歌曲分词 组成语料库\n    word.sad <- lapply(str1, removeEnglish)\n    word.sad <- lapply(word.sad, segmentCN)\n    corpus.sad <- Corpus(VectorSource(word.sad))\n\n    # 甜蜜歌曲分词 组成语料库\n    word.sweet <- lapply(str2, removeEnglish)\n    word.sweet <- lapply(word.sweet, segmentCN)\n    corpus.sweet <- Corpus(VectorSource(word.sweet))\n\n    # 合成预料库\n    corpus <- c(corpus.sad, corpus.sweet)\n    return(corpus)\n}\n\n\ncorpus <- makeCorpus(Infor.sweet$lyric, Infor.sad$lyric)\n\n```\n\n## 4 document-term matrix 函数实现\n要将文本信息转为可以给各种分类计算的信息，首先要把文本信息转为各种能计算的数字。document-term matrix每一列是一个词语，每一行是词频数，当然一般用TF-IDF作为特征权值计算。document-term 矩阵就是分类算法的特征矩阵，只是没给每一个数据集标上所属的类别。\n```{r}\ndtm <- function(corpus, tfidf = FALSE) {\n\n    ## 读取停止词\n    mystopwords <- readLines(\"Data/stopwords.txt\")\n    if (tfidf == TRUE) {\n        ## 文档-词矩阵 词的长度大于1就纳入矩阵\n        cor.dtm <- DocumentTermMatrix(corpus, control = list(wordLengths = c(2, \n            Inf), stopwords = mystopwords, weighting = weightTfIdf))\n    } else {\n        cor.dtm <- DocumentTermMatrix(corpus, control = list(wordLengths = c(2, \n            Inf), stopwords = mystopwords))\n    }\n    ## 去掉稀疏矩阵中低频率的词\n    cor.dtm <- removeSparseTerms(cor.dtm, 0.98)\n\n    ## 使得每一行至少有一个词不为0 rowTotals <- apply(cor.dtm, 1, sum) cor.dtm <-\n    ## cor.dtm[rowTotals > 0]\n    return(cor.dtm)\n}\n\n```\n\n形成文本词条矩阵dtm\n```{r}\ncorpus.dtm <- dtm(corpus)\ncorpus.dtm.tfidf <- dtm(corpus, tfidf = TRUE)\n\n```\n\n## 5 使用算法对歌词进行情感的分类\n首先对每一首标上对应的类别。数据集中前764首歌曲是伤感歌曲，后面861首是甜蜜的歌曲。然后确定测试集和训练集范围。\n\n然后传入一个document-term matrix，然后使用SVM和随机森林算法对输入的数据进行分类。\n\n```{r}\nalgorithm_summary <- function(dtm) {\n\n    # 类别向量\n    label <- factor(c(rep(\"sad\", 764), c(rep(\"sweet\", 861))))\n    # 从伤感歌词中挑选64首作为测试集，同理甜蜜类挑选61首作为测试集\n    sad.test <- sample(1:764, 64, replace = FALSE)\n    sweet.test <- sample(765:1625, 61, replace = FALSE)\n    testSize <- c(sad.test, sweet.test)\n    trainSize <- 1:1625\n    trainSize <- trainSize[-testSize]\n\n    # create a container\n    container.song <- create_container(dtm, label, trainSize = trainSize, testSize = testSize, \n        virgin = FALSE)\n\n    # training models\n    SVM.song <- train_model(container.song, \"SVM\")\n    RF.song <- train_model(container.song, \"RF\")\n\n    # classifying data using trained models\n    SVM_CLASSIFY.song <- classify_model(container.song, SVM.song)\n    RF_CLASSIFY.song <- classify_model(container.song, RF.song)\n\n    SVM_result <- create_precisionRecallSummary(container = container.song, \n        classification_results = SVM_CLASSIFY.song)\n    RF_result <- create_precisionRecallSummary(container = container.song, classification_results = RF_CLASSIFY.song)\n    return(list(SVM_RESULT = SVM_result, RF_RESULT = RF_result))\n}\n\n```\n\n使用algorithm_summary函数对歌曲进行分类，我们看一下分类结果。\n```{r}\nresult_all_corpus <- algorithm_summary(corpus.dtm.tfidf)\nresult_all_corpus\n```\n\n## 词云\n```{r}\n## song.sweet.wordcloud <- wordcloud(corpus.dtm.tfidf)\n```\n\n\n## 5 特征提取\n\n\n采用随机森林算法选取前100个重要的词语，`subset`即是前100有重要分类信息的词语\n\n\n```{r}\n# 转为data frame\ncorpus.df <- as.data.frame(inspect(corpus.dtm.tfidf),encoding=\"Unicode\",stringsAsFactors=FALSE)\n\n\n## 随机森林算法选取前100个重要的词语\nlabel<-factor(c(rep(\"sad\",764),c(rep(\"sweet\",861))))\nweights.rf <- random.forest.importance(label~., corpus.df, 1)\nsubset <- cutoff.k(weights.rf, 100)\n## 把提取的特征作为新的docment-term matrix\nfeature.df <- as.DocumentTermMatrix(corpus.df[subset],weighting=weightTf)\n```\n让我们再次看看分类效果\n\n\n```{r}\nresult_feature <- algorithm_summary(feature.df)\nresult_feature\n```\n\n\n \n## 词云\n```{r}\nnew_wordcolud <- wordcloud(feature.df)\n```",
    "created" : 1404126301749.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1952994048",
    "id" : "E355EBF4",
    "lastKnownWriteTime" : 1404442184,
    "path" : "~/GitHub/My-DataMining/TextMining/CaseStudy.Rmd",
    "project_path" : "CaseStudy.Rmd",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_markdown"
}